# A Survey of Large Language Models for Arabic Language and its Dialects
<div align="center">
  <a href="https://arxiv.org/abs/2410.20238">
    <img src="https://img.shields.io/badge/arXiv-Paper%20Download-b31b1b.svg" alt="Download from arXiv">
  </a>
</div>
This survey offers a comprehensive overview of Large Language Models (LLMs) designed for Arabic language and its dialects. It covers key architectures, including encoder-only, decoder-only, and encoder-decoder models, along with the datasets used for pre-training, spanning Classical Arabic, Modern Standard Arabic, and Dialectal Arabic. The study also explores monolingual, bilingual, and multilingual LLMs, analyzing their architectures and performance across downstream tasks, such as sentiment analysis, named entity recognition, and question answering. Furthermore, it assesses the openness of Arabic LLMs based on factors, such as source code availability, training data, model weights, and documentation. The survey highlights the need for more diverse dialectal datasets and attributes the importance of openness for research reproducibility and transparency. It concludes by identifying key challenges and opportunities for future research and stressing the need for more inclusive and representative models.

###Aspects of the survey
![Arabic LLM Survey](https://github.com/iwan-rg/ArabicLLMs/blob/main/Arabic%20LLM%20Survey.png?raw=true)

###Geographic Distribution and Development of Arabic LLMs. Model names with the same color indicate collaborative development efforts between different countries.

![Geographic Distribution and Development of Arabic LLMs. Model names with the same color indicate collaborative development efforts between different countries.](https://github.com/iwan-rg/ArabicLLMs/blob/main/LLM%20Map.png?raw=true)

## Monolingual Arabic LLMs
AraBERT
MARBERT
ARBERT
QARiB
SudaBERT
AraELECTRA
AraGPT2
CAMeLBERT
JABER
SABER
AraBART
AraLegal-BERT
AraRoBERTa
DziriBERT
TunBERT
DarijaBERT
AraMUS
MorRoBERTa
MorrBERT
JASMINE
AraQA
ArabianGPT
AraPOEMBERT
SaudiBERT
AlcLaM
AraStories
EgyBERT
Atlas-Chat

## Bilingual Arabic LLMS
GigaBERT 
JAIS 
AceGPT
ALLaM

## Multilingual Arabic LLMS
ArabicBERT 	
AraT5 

## Citation
Please cite our paper if you use it in your work:

**BibTeX**
```bibtex
@misc{mashaabi2024survey,
      title={A Survey of Large Language Models for Arabic Language and its Dialects}, 
      author={Malak Mashaabi and Shahad Al-Khalifa and Hend Al-Khalifa},
      year={2024},
      institution={iWAN Research Group, College of Computer and Information Sciences, King Saud University},
      url={https://arxiv.org/abs/2410.20238}, 
}
